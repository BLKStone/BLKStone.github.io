<!doctype html>
<html class="theme-next use-motion theme-next-mist">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>


<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.3"/>


    <meta name="description" content="关于计算机科学的学习经历与精彩文章分享。" />



  <meta name="keywords" content="Ubuntu,转载," />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.3" />



<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: 'Mist',
    analytics: {
      google: ''
    },
    sidebar: 'post'
  };
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?351a523b2429a0dda1b90bb708a00fad";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>



  <title> Ubuntu 14.04 安装 Hadoop 2.6（单机模式） // Neurohazard </title>
</head>

<body>
  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->

  <div class="container one-column page-post-detail">
    <div class="headband"></div>

    <div id="header" class="header">
      <div class="header-inner">
        <h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand">
      <span class="logo">
        <i class="icon-logo"></i>
      </span>
      <span class="site-title">Neurohazard</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<div class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/">
            <i class="menu-item-icon icon-home"></i> <br />
            首頁
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            <i class="menu-item-icon icon-about"></i> <br />
            關於
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            <i class="menu-item-icon icon-archives"></i> <br />
            歸檔
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            <i class="menu-item-icon icon-tags"></i> <br />
            標籤
          </a>
        </li>
      
        
        <li class="menu-item menu-item-friend">
          <a href="/friend">
            <i class="menu-item-icon icon-friend"></i> <br />
            友情鏈接
          </a>
        </li>
      
        
        <li class="menu-item menu-item-reading-list">
          <a href="/reading-list">
            <i class="menu-item-icon icon-reading-list"></i> <br />
            閱讀清單
          </a>
        </li>
      
    </ul>
  

  
</div>


      </div>
    </div>

    <div id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content">
          

  <div id="posts" class="posts-expand">
    

  <div class="post post-type-normal ">
    <div class="post-header">

      
      
        <h1 class="post-title">
          
          
            
              Ubuntu 14.04 安装 Hadoop 2.6（单机模式）
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          發表於 2015-10-26
        </span>

        
          <span class="post-category">
            &nbsp; | &nbsp; 分類於
            
              <a href="/categories/系统使用/">系统使用</a>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
            &nbsp; | &nbsp;
            <a href="/2015/10/26/ubuntu-hadoop/#comments" >
              <span class="post-comments-count ds-thread-count" data-thread-key="2015/10/26/ubuntu-hadoop/"></span>
            </a>
          </span>
          
        
      </div>
    </div>

    <div class="post-body">

      
      

      
        <blockquote>
<p>转载自<br><a href="http://www.bogotobogo.com/Hadoop/BigData_hadoop_Install_on_ubuntu_single_node_cluster.php" target="_blank" rel="external">http://www.bogotobogo.com/Hadoop/BigData_hadoop_Install_on_ubuntu_single_node_cluster.php</a></p>
</blockquote>
<h1 id="Installing_Java">Installing Java</h1><p>Hadoop framework is written in Java!!<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>cd ~</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update the source list</span></span><br><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo apt-get update</span><br><span class="line"></span><br><span class="line"><span class="comment"># The OpenJDK project is the default version of Java </span></span><br><span class="line"><span class="comment"># that is provided from a supported Ubuntu repository.</span></span><br><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo apt-get install default-jdk</span><br><span class="line"></span><br><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>java -version</span><br><span class="line">java version <span class="string">"1.7.0_65"</span></span><br><span class="line"><span class="constant">OpenJDK Runtime Environment </span>(<span class="constant">IcedTea </span><span class="number">2.5</span>.<span class="number">3</span>) (<span class="number">7</span>u71-<span class="number">2.5</span>.<span class="number">3</span>-0ubuntu<span class="number">0</span>.<span class="number">14.04</span>.<span class="number">1</span>)</span><br><span class="line"><span class="constant">OpenJDK </span><span class="number">64</span>-<span class="constant">Bit Server VM </span>(build <span class="number">24.65</span>-b04, mixed mode)</span><br></pre></td></tr></table></figure></p>
<h1 id="Adding_a_dedicated_Hadoop_user">Adding a dedicated Hadoop user</h1><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">k@laptop:~$ sudo addgroup hadoop</span><br><span class="line"><span class="type">Adding</span> group `hadoop' (<span class="type">GID</span> <span class="number">1002</span>) ...</span><br><span class="line"><span class="type">Done</span>.</span><br><span class="line"></span><br><span class="line">k@laptop:~$ sudo adduser --ingroup hadoop hduser</span><br><span class="line"><span class="type">Adding</span> user `hduser' ...</span><br><span class="line"><span class="type">Adding</span> <span class="keyword">new</span> user `hduser' (<span class="number">1001</span>) <span class="keyword">with</span> group `hadoop' ...</span><br><span class="line"><span class="type">Creating</span> home directory `/home/hduser' ...</span><br><span class="line"><span class="type">Copying</span> files from `/etc/skel' ...</span><br><span class="line"><span class="type">Enter</span> <span class="keyword">new</span> <span class="type">UNIX</span> password: </span><br><span class="line"><span class="type">Retype</span> <span class="keyword">new</span> <span class="type">UNIX</span> password: </span><br><span class="line">passwd: password updated successfully</span><br><span class="line"><span class="type">Changing</span> the user information <span class="keyword">for</span> hduser</span><br><span class="line"><span class="type">Enter</span> the <span class="keyword">new</span> <span class="keyword">value</span>, <span class="keyword">or</span> press <span class="type">ENTER</span> <span class="keyword">for</span> the default</span><br><span class="line">    <span class="type">Full</span> <span class="type">Name</span> <span class="literal">[]</span>: </span><br><span class="line">    <span class="type">Room</span> <span class="type">Number</span> <span class="literal">[]</span>: </span><br><span class="line">    <span class="type">Work</span> <span class="type">Phone</span> <span class="literal">[]</span>: </span><br><span class="line">    <span class="type">Home</span> <span class="type">Phone</span> <span class="literal">[]</span>: </span><br><span class="line">    <span class="type">Other</span> <span class="literal">[]</span>: </span><br><span class="line"><span class="type">Is</span> the information correct? [<span class="type">Y</span>/n] <span class="type">Y</span></span><br></pre></td></tr></table></figure>
<h1 id="Installing_SSH">Installing SSH</h1><p>ssh has two main components:</p>
<ol>
<li>ssh : The command we use to connect to remote machines - the client.</li>
<li>sshd : The daemon that is running on the server and allows clients to connect to the server.</li>
</ol>
<p>The <code>ssh</code> is pre-enabled on Linux, but in order to start <code>sshd</code> daemon, we need to install ssh first. Use this command to do that :</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo apt-get install ssh</span><br></pre></td></tr></table></figure>
<p>This will install ssh on our machine. If we get something similar to the following, we can think it is setup properly:<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>which ssh</span><br><span class="line">/usr/bin/ssh</span><br><span class="line"></span><br><span class="line">k<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>which sshd</span><br><span class="line">/usr/sbin/sshd</span><br></pre></td></tr></table></figure></p>
<h1 id="Create_and_Setup_SSH_Certificates">Create and Setup SSH Certificates</h1><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">k<span class="comment">@laptop:~$ su hduser</span></span><br><span class="line">Password: </span><br><span class="line">k<span class="comment">@laptop:~$ ssh-keygen -t rsa -P ""</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/home/hduser/.ssh/id_rsa): </span><br><span class="line">Created directory '/home/hduser/.ssh'.</span><br><span class="line">Your identification has been saved in /home/hduser/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /home/hduser/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">50:6b:f3:fc:0f:32:bf:30:79:c2:41:71:26:cc:7d:e3 hduser<span class="comment">@laptop</span></span><br><span class="line">The key's randomart image is:</span><br><span class="line">+--[ RSA 2048]----+</span><br><span class="line">|<span class="string">        .oo.o    </span>|</span><br><span class="line">|<span class="string">       . .o=. o  </span>|</span><br><span class="line">|<span class="string">      . + .  o . </span>|</span><br><span class="line">|<span class="string">       o =    E  </span>|</span><br><span class="line">|<span class="string">        S +      </span>|</span><br><span class="line">|<span class="string">         . +     </span>|</span><br><span class="line">|<span class="string">          O +    </span>|</span><br><span class="line">|<span class="string">           O o   </span>|</span><br><span class="line">|<span class="string">            o..  </span>|</span><br><span class="line">+-----------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hduser<span class="comment">@laptop:/home/k$ cat $HOME/.ssh/id_rsa.pub &gt;&gt; $HOME/.ssh/authorized_keys</span></span><br></pre></td></tr></table></figure>
<p>The second command adds the newly created key to the list of authorized keys so that Hadoop can use ssh without prompting for a password.</p>
<p>We can check if ssh works:<br><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:/home/k$ ssh localhost</span><br><span class="line">The authenticity <span class="keyword">of</span> host <span class="attribute">'localhost</span> (<span class="number">127.0</span>.<span class="number">0.1</span>)' can<span class="attribute">'t</span> be established.</span><br><span class="line">ECDSA key fingerprint <span class="keyword">is</span> e1:<span class="number">8</span>b:a0:a5:<span class="number">75</span>:ef:f4:b4:<span class="number">5</span>e:a9:ed:be:<span class="number">64</span>:be:<span class="number">5</span>c:<span class="number">2</span>f.</span><br><span class="line">Are you sure you want <span class="keyword">to</span> continue connecting (yes/no)? yes</span><br><span class="line">Warning: Permanently added <span class="attribute">'localhost</span>' (ECDSA) <span class="keyword">to</span> the list <span class="keyword">of</span> known hosts.</span><br><span class="line">Welcome <span class="keyword">to</span> Ubuntu <span class="number">14.04</span>.<span class="number">1</span> LTS (GNU/Linux <span class="number">3.13</span>.<span class="number">0</span>-<span class="number">40</span>-<span class="keyword">generic</span> x86_64)</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h1 id="Install_Hadoop">Install Hadoop</h1><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>wget <span class="symbol">http:</span>/<span class="regexp">/mirrors.sonic.net/apache</span><span class="regexp">/hadoop/common</span><span class="regexp">/hadoop-2.6.0/hadoop</span>-<span class="number">2.6</span>.<span class="number">0</span>.tar.gz</span><br><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>tar xvzf hadoop-<span class="number">2.6</span>.<span class="number">0</span>.tar.gz</span><br></pre></td></tr></table></figure>
<p>We want to move the Hadoop installation to the /usr/local/hadoop directory using the following command:<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:~/hadoop-<span class="number">2.6</span>.0$ sudo mv * /usr/<span class="keyword">local</span>/hadoop</span><br><span class="line">[sudo] password <span class="keyword">for</span> hduser: </span><br><span class="line">hduser <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">the</span> sudoers <span class="type">file</span>.  This incident will be reported.</span><br></pre></td></tr></table></figure></p>
<p>这里的错误可以不烦，只要之前将hduser加到sudoer用户组中即可。</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~/hadoop-</span><span class="number">2.6</span>.<span class="number">0</span><span class="variable">$ </span>su k</span><br><span class="line"><span class="constant">Password:</span> </span><br><span class="line"></span><br><span class="line">k<span class="variable">@laptop</span><span class="symbol">:/home/hduser</span><span class="variable">$ </span>sudo adduser hduser sudo</span><br><span class="line">[sudo] password <span class="keyword">for</span> <span class="symbol">k:</span> </span><br><span class="line"><span class="constant">Adding </span>user `hduser<span class="string">' to group `sudo'</span> ...</span><br><span class="line"><span class="constant">Adding </span>user hduser to group sudo</span><br><span class="line"><span class="constant">Done.</span></span><br></pre></td></tr></table></figure>
<p>Now, the hduser has root priviledge, we can move the Hadoop installation to the /usr/local/hadoop directory without any problem:</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">k<span class="annotation">@laptop</span>:<span class="regexp">/home/</span>hduser$ sudo su hduser</span><br><span class="line"></span><br><span class="line">hduser<span class="annotation">@laptop</span>:<span class="regexp">~/hadoop-2.6.0$ sudo mv * /</span>usr<span class="regexp">/local/</span>hadoop </span><br><span class="line">hduser<span class="annotation">@laptop</span>:<span class="regexp">~/hadoop-2.6.0$ sudo chown -R hduser:hadoop /</span>usr<span class="regexp">/local/</span>hadoop</span><br></pre></td></tr></table></figure>
<h1 id="Setup_Configuration_Files">Setup Configuration Files</h1><p>The following files will have to be modified to complete the Hadoop setup:</p>
<ol>
<li>~/.bashrc</li>
<li>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</li>
<li>/usr/local/hadoop/etc/hadoop/core-site.xml</li>
<li>/usr/local/hadoop/etc/hadoop/mapred-site.xml.template</li>
<li>/usr/local/hadoop/etc/hadoop/hdfs-site.xml</li>
</ol>
<h2 id="~/-bashrc">~/.bashrc</h2><p>Before editing the .bashrc file in our home directory, we need to find the path where Java has been installed to set the JAVA_HOME environment variable using the following command:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop <span class="operator"><span class="keyword">update</span>-alternatives <span class="comment">--config java</span></span><br><span class="line">There <span class="keyword">is</span> <span class="keyword">only</span> one alternative <span class="keyword">in</span> link <span class="keyword">group</span> java (providing /usr/<span class="keyword">bin</span>/java): /usr/lib/jvm/java-<span class="number">7</span>-openjdk-amd64/jre/<span class="keyword">bin</span>/java</span><br><span class="line">Nothing <span class="keyword">to</span> configure.</span></span><br></pre></td></tr></table></figure></p>
<p>Now we can append the following to the end of ~/.bashrc:<br>这里也可以用其他编辑器，就方便性而言还是vim而不是vi。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:~$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP VARIABLES START</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-<span class="number">7</span>-openjdk-amd64</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_INSTALL</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_INSTALL</span>/sbin</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_INSTALL</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_INSTALL</span>/lib"</span></span><br><span class="line"><span class="comment">#HADOOP VARIABLES END</span></span><br><span class="line"></span><br><span class="line">hduser@laptop:~$ <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>note that the JAVA_HOME should be set as the path just before the ‘…/bin/‘:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="annotation">@ubuntu</span>-<span class="string">VirtualBox:</span>~$ javac -version</span><br><span class="line">javac <span class="number">1.7</span>.0_75</span><br><span class="line"></span><br><span class="line">hduser<span class="annotation">@ubuntu</span>-<span class="string">VirtualBox:</span>~$ which javac</span><br><span class="line"><span class="regexp">/usr/</span>bin/javac</span><br><span class="line"></span><br><span class="line">hduser<span class="annotation">@ubuntu</span>-<span class="string">VirtualBox:</span>~$ readlink -f <span class="regexp">/usr/</span>bin/javac</span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/jvm/</span>java-<span class="number">7</span>-openjdk-amd64<span class="regexp">/bin/</span>javac</span><br></pre></td></tr></table></figure></p>
<h2 id="/usr/local/hadoop/etc/hadoop/hadoop-env-sh">/usr/local/hadoop/etc/hadoop/hadoop-env.sh</h2><p>We need to set JAVA_HOME by modifying hadoop-env.sh files<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="annotation">@laptop</span>:~$ vi <span class="regexp">/usr/</span>local<span class="regexp">/hadoop/</span>etc<span class="regexp">/hadoop/</span>hadoop-env.sh</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=<span class="regexp">/usr/</span>lib<span class="regexp">/jvm/</span>java-<span class="number">7</span>-openjdk-amd64</span><br></pre></td></tr></table></figure></p>
<h2 id="/usr/local/hadoop/etc/hadoop/core-site-xml">/usr/local/hadoop/etc/hadoop/core-site.xml</h2><p>The /usr/local/hadoop/etc/hadoop/core-site.xml file contains configuration properties that Hadoop uses when starting up.<br>This file can be used to override the default settings that Hadoop starts with.</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo mkdir -p /app/hadoop/tmp</span><br><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo chown <span class="symbol">hduser:</span>hadoop /app/hadoop/tmp</span><br></pre></td></tr></table></figure>
<p>Open the file and enter the following in between the <configuration></configuration> tag:<br><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:~$ vi /usr/local/hadoop/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line"><span class="variable">&lt;configuration&gt;</span></span><br><span class="line"> <span class="variable">&lt;property&gt;</span></span><br><span class="line">  <span class="variable">&lt;name&gt;</span>hadoop.tmp.dir<span class="variable">&lt;/name&gt;</span></span><br><span class="line">  <span class="variable">&lt;value&gt;</span>/app/hadoop/tmp<span class="variable">&lt;/value&gt;</span></span><br><span class="line">  <span class="variable">&lt;description&gt;</span>A base <span class="keyword">for</span> other temporary directories.<span class="variable">&lt;/description&gt;</span></span><br><span class="line"> <span class="variable">&lt;/property&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="variable">&lt;property&gt;</span></span><br><span class="line">  <span class="variable">&lt;name&gt;</span>fs.<span class="keyword">default</span>.name<span class="variable">&lt;/name&gt;</span></span><br><span class="line">  <span class="variable">&lt;value&gt;</span>hdfs://localhost:<span class="number">54310</span><span class="variable">&lt;/value&gt;</span></span><br><span class="line">  <span class="variable">&lt;description&gt;</span>The name of the <span class="keyword">default</span> file system.  A URI whose</span><br><span class="line">  scheme and authority determine the FileSystem implementation.  The</span><br><span class="line">  uri's scheme determines the config property (fs.SCHEME.impl) naming</span><br><span class="line">  the FileSystem implementation class.  The uri's authority is used <span class="keyword">to</span></span><br><span class="line">  determine the host, <span class="keyword">port</span>, etc. <span class="keyword">for</span> a filesystem.<span class="variable">&lt;/description&gt;</span></span><br><span class="line"> <span class="variable">&lt;/property&gt;</span></span><br><span class="line"><span class="variable">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="/usr/local/hadoop/etc/hadoop/mapred-site-xml">/usr/local/hadoop/etc/hadoop/mapred-site.xml</h2><p>By default, the /usr/local/hadoop/etc/hadoop/ folder contains<br>/usr/local/hadoop/etc/hadoop/mapred-site.xml.template<br>file which has to be renamed/copied with the name mapred-site.xml:</p>
<figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:~$ cp /usr/local/hadoop/etc/hadoop/mapred-site.xml.<span class="keyword">template</span> /usr/local/hadoop/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>The mapred-site.xml file is used to specify which framework is being used for MapReduce.<br>We need to enter the following content in between the <configuration></configuration> tag:<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"> &lt;<span class="keyword">property</span>&gt;</span><br><span class="line">  &lt;<span class="property">name</span>&gt;mapred.job.tracker&lt;/<span class="property">name</span>&gt;</span><br><span class="line">  &lt;value&gt;localhost:<span class="number">54311</span>&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;The host <span class="keyword">and</span> port <span class="keyword">that</span> <span class="keyword">the</span> MapReduce job tracker runs</span><br><span class="line">  <span class="keyword">at</span>.  If <span class="string">"local"</span>, <span class="keyword">then</span> jobs are <span class="command">run</span> <span class="keyword">in</span>-process <span class="keyword">as</span> a single map</span><br><span class="line">  <span class="keyword">and</span> reduce task.</span><br><span class="line">  &lt;/description&gt;</span><br><span class="line"> &lt;/<span class="keyword">property</span>&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="/usr/local/hadoop/etc/hadoop/hdfs-site-xml">/usr/local/hadoop/etc/hadoop/hdfs-site.xml</h2><p>The /usr/local/hadoop/etc/hadoop/hdfs-site.xml file needs to be configured for each host in the cluster that is being used.<br>It is used to specify the directories which will be used as the namenode and the datanode on that host.</p>
<p>Before editing this file, we need to create two directories which will contain the namenode and the datanode for this Hadoop installation.<br>This can be done using the following commands:<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo mkdir -p /usr/local/hadoop_store/hdfs/namenode</span><br><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo mkdir -p /usr/local/hadoop_store/hdfs/datanode</span><br><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:~</span><span class="variable">$ </span>sudo chown -<span class="constant">R </span><span class="symbol">hduser:</span>hadoop /usr/local/hadoop_store</span><br></pre></td></tr></table></figure></p>
<p>Open the file and enter the following content in between the <configuration></configuration> tag:<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:~$ vi /usr/<span class="keyword">local</span>/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"> &lt;<span class="keyword">property</span>&gt;</span><br><span class="line">  &lt;<span class="property">name</span>&gt;dfs.replication&lt;/<span class="property">name</span>&gt;</span><br><span class="line">  &lt;value&gt;<span class="number">1</span>&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;Default block replication.</span><br><span class="line">  The actual <span class="type">number</span> <span class="keyword">of</span> replications can be specified when <span class="keyword">the</span> <span class="type">file</span> <span class="keyword">is</span> created.</span><br><span class="line">  The default <span class="keyword">is</span> used <span class="keyword">if</span> replication <span class="keyword">is</span> <span class="keyword">not</span> specified <span class="keyword">in</span> create <span class="property">time</span>.</span><br><span class="line">  &lt;/description&gt;</span><br><span class="line"> &lt;/<span class="keyword">property</span>&gt;</span><br><span class="line"> &lt;<span class="keyword">property</span>&gt;</span><br><span class="line">   &lt;<span class="property">name</span>&gt;dfs.namenode.<span class="property">name</span>.dir&lt;/<span class="property">name</span>&gt;</span><br><span class="line">   &lt;value&gt;<span class="type">file</span>:/usr/<span class="keyword">local</span>/hadoop_store/hdfs/namenode&lt;/value&gt;</span><br><span class="line"> &lt;/<span class="keyword">property</span>&gt;</span><br><span class="line"> &lt;<span class="keyword">property</span>&gt;</span><br><span class="line">   &lt;<span class="property">name</span>&gt;dfs.datanode.data.dir&lt;/<span class="property">name</span>&gt;</span><br><span class="line">   &lt;value&gt;<span class="type">file</span>:/usr/<span class="keyword">local</span>/hadoop_store/hdfs/datanode&lt;/value&gt;</span><br><span class="line"> &lt;/<span class="keyword">property</span>&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="Format_the_New_Hadoop_Filesystem">Format the New Hadoop Filesystem</h1><p>Now, the Hadoop file system needs to be formatted so that we can start to use it. The format command should be issued with write permission since it creates current directory<br>under /usr/local/hadoop_store/hdfs/namenode folder:<br><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="comment">@laptop:~$ hadoop namenode -format</span></span><br><span class="line">DEPRECATED: Use of this script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command for it.</span><br><span class="line"></span><br><span class="line">15/04/18 14:43:03 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/<span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span></span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = laptop/192.168.1.1</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 2.6.0</span><br><span class="line">STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop</span><br><span class="line">...</span><br><span class="line">STARTUP_MSG:   java = 1.7.0_65</span><br><span class="line"><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span>/</span><br><span class="line">15/04/18 14:43:03 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]</span><br><span class="line">15/04/18 14:43:03 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">15/04/18 14:43:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Formatting using clusterid: CID-e2f515ac-33da-45bc-8466-5b1100a2bf7f</span><br><span class="line">15/04/18 14:43:09 INFO namenode.FSNamesystem: No KeyProvider found.</span><br><span class="line">15/04/18 14:43:09 INFO namenode.FSNamesystem: fsLock is fair:true</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: The block deletion will start around 2015 Apr 18 14:43:10</span><br><span class="line">15/04/18 14:43:10 INFO util.GSet: Computing capacity for map BlocksMap</span><br><span class="line">15/04/18 14:43:10 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/04/18 14:43:10 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB</span><br><span class="line">15/04/18 14:43:10 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: defaultReplication         = 1</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: encryptDataTransfer        = false</span><br><span class="line">15/04/18 14:43:10 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class="line">15/04/18 14:43:10 INFO namenode.FSNamesystem: fsOwner             = hduser (auth:SIMPLE)</span><br><span class="line">15/04/18 14:43:10 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class="line">15/04/18 14:43:10 INFO namenode.FSNamesystem: isPermissionEnabled = true</span><br><span class="line">15/04/18 14:43:10 INFO namenode.FSNamesystem: HA Enabled: false</span><br><span class="line">15/04/18 14:43:10 INFO namenode.FSNamesystem: Append Enabled: true</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: Computing capacity for map INodeMap</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class="line">15/04/18 14:43:11 INFO namenode.NameNode: Caching file names occuring more than 10 times</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: Computing capacity for map cachedBlocks</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: capacity      = 2^18 = 262144 entries</span><br><span class="line">15/04/18 14:43:11 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class="line">15/04/18 14:43:11 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0</span><br><span class="line">15/04/18 14:43:11 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000</span><br><span class="line">15/04/18 14:43:11 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">15/04/18 14:43:11 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: Computing capacity for map NameNodeRetryCache</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB</span><br><span class="line">15/04/18 14:43:11 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class="line">15/04/18 14:43:11 INFO namenode.NNConf: ACLs enabled? false</span><br><span class="line">15/04/18 14:43:11 INFO namenode.NNConf: XAttrs enabled? true</span><br><span class="line">15/04/18 14:43:11 INFO namenode.NNConf: Maximum size of an xattr: 16384</span><br><span class="line">15/04/18 14:43:12 INFO namenode.FSImage: Allocated new BlockPoolId: BP-130729900-192.168.1.1-1429393391595</span><br><span class="line">15/04/18 14:43:12 INFO common.Storage: Storage directory /usr/local/hadoop_store/hdfs/namenode has been successfully formatted.</span><br><span class="line">15/04/18 14:43:12 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">15/04/18 14:43:12 INFO util.ExitUtil: Exiting with status 0</span><br><span class="line">15/04/18 14:43:12 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/<span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span></span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at laptop/192.168.1.1</span><br><span class="line"><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span><span class="keyword">*</span>/</span><br></pre></td></tr></table></figure></p>
<p>Note that hadoop namenode -format command should be executed once before we start using Hadoop.<br>If this command is executed again after Hadoop has been used, it’ll destroy all the data on the Hadoop file system.</p>
<h1 id="Starting_Hadoop">Starting Hadoop</h1><p>Now it’s time to start the newly installed single node cluster.<br>We can use start-all.sh or (start-dfs.sh and start-yarn.sh)</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">k@laptop:~$ cd /usr/local/hadoop/sbin</span><br><span class="line"></span><br><span class="line">k@laptop:/usr/local/hadoop/sbin$ ls</span><br><span class="line">distribute-exclude<span class="class">.sh</span>    start-all<span class="class">.cmd</span>        stop-balancer<span class="class">.sh</span></span><br><span class="line">hadoop-daemon<span class="class">.sh</span>         start-all<span class="class">.sh</span>         stop-dfs<span class="class">.cmd</span></span><br><span class="line">hadoop-daemons<span class="class">.sh</span>        start-balancer<span class="class">.sh</span>    stop-dfs<span class="class">.sh</span></span><br><span class="line">hdfs-config<span class="class">.cmd</span>          start-dfs<span class="class">.cmd</span>        stop-secure-dns<span class="class">.sh</span></span><br><span class="line">hdfs-config<span class="class">.sh</span>           start-dfs<span class="class">.sh</span>         stop-yarn<span class="class">.cmd</span></span><br><span class="line">httpfs<span class="class">.sh</span>                start-secure-dns<span class="class">.sh</span>  stop-yarn<span class="class">.sh</span></span><br><span class="line">kms<span class="class">.sh</span>                   start-yarn<span class="class">.cmd</span>       yarn-daemon<span class="class">.sh</span></span><br><span class="line">mr-jobhistory-daemon<span class="class">.sh</span>  start-yarn<span class="class">.sh</span>        yarn-daemons<span class="class">.sh</span></span><br><span class="line">refresh-namenodes<span class="class">.sh</span>     stop-all<span class="class">.cmd</span></span><br><span class="line">slaves<span class="class">.sh</span>                stop-all<span class="class">.sh</span></span><br><span class="line"></span><br><span class="line">k@laptop:/usr/local/hadoop/sbin$ sudo su hduser</span><br><span class="line"></span><br><span class="line">hduser@laptop:/usr/local/hadoop/sbin$ start-all<span class="class">.sh</span></span><br><span class="line">hduser@laptop:~$ start-all<span class="class">.sh</span></span><br><span class="line">This script is Deprecated. Instead use start-dfs<span class="class">.sh</span> and start-yarn<span class="class">.sh</span></span><br><span class="line"><span class="number">15</span>/<span class="number">04</span>/<span class="number">18</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">13</span> WARN util<span class="class">.NativeCodeLoader</span>: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line">Starting namenodes on [localhost]</span><br><span class="line">localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hduser-namenode-laptop<span class="class">.out</span></span><br><span class="line">localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hduser-datanode-laptop<span class="class">.out</span></span><br><span class="line">Starting secondary namenodes [<span class="number">0.0</span>.<span class="number">0.0</span>]</span><br><span class="line"><span class="number">0.0</span>.<span class="number">0.0</span>: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-hduser-secondarynamenode-laptop<span class="class">.out</span></span><br><span class="line"><span class="number">15</span>/<span class="number">04</span>/<span class="number">18</span> <span class="number">16</span>:<span class="number">43</span>:<span class="number">58</span> WARN util<span class="class">.NativeCodeLoader</span>: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /usr/local/hadoop/logs/yarn-hduser-resourcemanager-laptop<span class="class">.out</span></span><br><span class="line">localhost: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-hduser-nodemanager-laptop.out</span><br></pre></td></tr></table></figure>
<p>We can check if it’s really up and running:<br><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:/usr/local/hadoop/sbin</span><span class="variable">$ </span>jps</span><br><span class="line"><span class="number">9026</span> <span class="constant">NodeManager</span></span><br><span class="line"><span class="number">7348</span> <span class="constant">NameNode</span></span><br><span class="line"><span class="number">9766</span> <span class="constant">Jps</span></span><br><span class="line"><span class="number">8887</span> <span class="constant">ResourceManager</span></span><br><span class="line"><span class="number">7507</span> <span class="constant">DataNode</span></span><br></pre></td></tr></table></figure></p>
<p>The output means that we now have a functional instance of Hadoop running on our VPS (Virtual private server).</p>
<p>Another way to check is using netstat:<br><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:~$ netstat -plten | grep java</span><br><span class="line">(Not all processes could be identified, non-owned process info</span><br><span class="line"> will not be shown, you would have to be root to see it all.)</span><br><span class="line">tcp        0      <span class="number">0 0.0.0</span>.<span class="number">0:50020</span>           <span class="number">0.0.0.0</span>:*               LISTEN      1001       <span class="number">1843372</span>     10605/java      </span><br><span class="line">tcp        0      <span class="number">0 127.0.0</span>.<span class="number">1:54310</span>         <span class="number">0.0.0.0</span>:*               LISTEN      1001       <span class="number">1841277</span>     10447/java      </span><br><span class="line">tcp        0      <span class="number">0 0.0.0</span>.<span class="number">0:50090</span>           <span class="number">0.0.0.0</span>:*               LISTEN      1001       <span class="number">1841130</span>     10895/java      </span><br><span class="line">tcp        0      <span class="number">0 0.0.0</span>.<span class="number">0:50070</span>           <span class="number">0.0.0.0</span>:*               LISTEN      1001       <span class="number">1840196</span>     10447/java      </span><br><span class="line">tcp        0      <span class="number">0 0.0.0</span>.<span class="number">0:50010</span>           <span class="number">0.0.0.0</span>:*               LISTEN      1001       <span class="number">1841320</span>     10605/java      </span><br><span class="line">tcp        0      <span class="number">0 0.0.0</span>.<span class="number">0:50075</span>           <span class="number">0.0.0.0</span>:*               LISTEN      1001       <span class="number">1841646</span>     10605/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8040                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1845543</span>     11383/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8042                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1845551</span>     11383/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8088                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1842110</span>     11252/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:49630                <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1845534</span>     11383/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8030                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1842036</span>     11252/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8031                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1842005</span>     11252/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8032                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1842100</span>     11252/java      </span><br><span class="line">tcp6       0      0 <span class="number">::</span>:8033                 <span class="number">::</span>:*                    LISTEN      1001       <span class="number">1842162</span>     11252/java</span><br></pre></td></tr></table></figure></p>
<h1 id="Stopping_Hadoop">Stopping Hadoop</h1><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ pwd</span><br><span class="line">/usr/local/hadoop/sbin</span><br><span class="line"></span><br><span class="line">$ ls</span><br><span class="line">distribute-exclude<span class="class">.sh</span>  httpfs<span class="class">.sh</span>                start-all<span class="class">.sh</span>         start-yarn<span class="class">.cmd</span>    stop-dfs<span class="class">.cmd</span>        yarn-daemon<span class="class">.sh</span></span><br><span class="line">hadoop-daemon<span class="class">.sh</span>       mr-jobhistory-daemon<span class="class">.sh</span>  start-balancer<span class="class">.sh</span>    start-yarn<span class="class">.sh</span>     stop-dfs<span class="class">.sh</span>         yarn-daemons<span class="class">.sh</span></span><br><span class="line">hadoop-daemons<span class="class">.sh</span>      refresh-namenodes<span class="class">.sh</span>     start-dfs<span class="class">.cmd</span>        stop-all<span class="class">.cmd</span>      stop-secure-dns<span class="class">.sh</span></span><br><span class="line">hdfs-config<span class="class">.cmd</span>        slaves<span class="class">.sh</span>                start-dfs<span class="class">.sh</span>         stop-all<span class="class">.sh</span>       stop-yarn<span class="class">.cmd</span></span><br><span class="line">hdfs-config<span class="class">.sh</span>         start-all<span class="class">.cmd</span>            start-secure-dns<span class="class">.sh</span>  stop-balancer<span class="class">.sh</span>  stop-yarn.sh</span><br></pre></td></tr></table></figure>
<p>We run stop-all.sh or (stop-dfs.sh and stop-yarn.sh) to stop all the daemons running on our machine:<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">hduser@laptop:/usr/local/hadoop/sbin$ pwd</span><br><span class="line">/usr/local/hadoop/sbin</span><br><span class="line">hduser@laptop:/usr/local/hadoop/sbin$ ls</span><br><span class="line">distribute-exclude<span class="class">.sh</span>  httpfs<span class="class">.sh</span>                start-all<span class="class">.cmd</span>      start-secure-dns<span class="class">.sh</span>  stop-balancer<span class="class">.sh</span>    stop-yarn<span class="class">.sh</span></span><br><span class="line">hadoop-daemon<span class="class">.sh</span>       kms<span class="class">.sh</span>                   start-all<span class="class">.sh</span>       start-yarn<span class="class">.cmd</span>       stop-dfs<span class="class">.cmd</span>        yarn-daemon<span class="class">.sh</span></span><br><span class="line">hadoop-daemons<span class="class">.sh</span>      mr-jobhistory-daemon<span class="class">.sh</span>  start-balancer<span class="class">.sh</span>  start-yarn<span class="class">.sh</span>        stop-dfs<span class="class">.sh</span>         yarn-daemons<span class="class">.sh</span></span><br><span class="line">hdfs-config<span class="class">.cmd</span>        refresh-namenodes<span class="class">.sh</span>     start-dfs<span class="class">.cmd</span>      stop-all<span class="class">.cmd</span>         stop-secure-dns<span class="class">.sh</span></span><br><span class="line">hdfs-config<span class="class">.sh</span>         slaves<span class="class">.sh</span>                start-dfs<span class="class">.sh</span>       stop-all<span class="class">.sh</span>          stop-yarn<span class="class">.cmd</span></span><br><span class="line">hduser@laptop:/usr/local/hadoop/sbin$ </span><br><span class="line">hduser@laptop:/usr/local/hadoop/sbin$ stop-all<span class="class">.sh</span></span><br><span class="line">This script is Deprecated. Instead use stop-dfs<span class="class">.sh</span> and stop-yarn<span class="class">.sh</span></span><br><span class="line"><span class="number">15</span>/<span class="number">04</span>/<span class="number">18</span> <span class="number">15</span>:<span class="number">46</span>:<span class="number">31</span> WARN util<span class="class">.NativeCodeLoader</span>: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line">Stopping namenodes on [localhost]</span><br><span class="line">localhost: stopping namenode</span><br><span class="line">localhost: stopping datanode</span><br><span class="line">Stopping secondary namenodes [<span class="number">0.0</span>.<span class="number">0.0</span>]</span><br><span class="line"><span class="number">0.0</span>.<span class="number">0.0</span>: no secondarynamenode to stop</span><br><span class="line"><span class="number">15</span>/<span class="number">04</span>/<span class="number">18</span> <span class="number">15</span>:<span class="number">46</span>:<span class="number">59</span> WARN util<span class="class">.NativeCodeLoader</span>: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line">stopping yarn daemons</span><br><span class="line">stopping resourcemanager</span><br><span class="line">localhost: stopping nodemanager</span><br><span class="line">no proxyserver to stop</span><br></pre></td></tr></table></figure></p>
<h1 id="Hadoop_Web_Interfaces">Hadoop Web Interfaces</h1><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hduser<span class="variable">@laptop</span><span class="symbol">:/usr/local/hadoop/sbin</span><span class="variable">$ </span>start-all.sh</span><br></pre></td></tr></table></figure>
<p><a href="http://localhost:50070/" target="_blank" rel="external">http://localhost:50070/</a> - web UI of the NameNode daemons</p>
<h1 id="参考资料">参考资料</h1><p>[1] <a href="">Hadoop 2.6 Installing on Ubuntu 14.04 (Single-Node Cluster) - 2015</a></p>

      
    </div>

    <div class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Ubuntu/"> #Ubuntu </a>
          
            <a href="/tags/转载/"> #转载 </a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2015/10/27/project-camerashy/">Project CameraShy</a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2015/10/25/python-c-c/">python调用C/C++</a>
            
          </div>
        </div>
      

      
      
    </div>
  </div>



    
      <div class="post-spread">
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      </div>
    

    
      <div class="comments" id="comments">
        
          <div class="ds-thread" data-thread-key="2015/10/26/ubuntu-hadoop/"
               data-title="Ubuntu 14.04 安装 Hadoop 2.6（单机模式）" data-url="http://blkstone.github.io/2015/10/26/ubuntu-hadoop/">
          </div>
        
      </div>
    
  </div>


        </div>

        
      </div>


      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <div id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目錄
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            本站概覽
          </li>
        </ul>
      

      <div class="site-overview">
        <div class="site-author motion-element">
          <img class="site-author-image" src="/images/avatar.jpg" alt="Ray" />
          <p class="site-author-name">Ray</p>
        </div>
        <p class="site-description motion-element">关于计算机科学的学习经历与精彩文章分享。</p>
        <div class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">135</span>
              <span class="site-state-item-name">文章</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">11</span>
              <span class="site-state-item-name">分類</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">57</span>
              <span class="site-state-item-name">標籤</span>
              </a>
          </div>

        </div>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
              <a href="https://github.com/BLKStone" target="_blank">GitHub</a>
            </span>
            
              <span class="links-of-author-item">
              <a href="http://blkstone.github.io/" target="_blank">Twitter</a>
            </span>
            
              <span class="links-of-author-item">
              <a href="http://blkstone.github.io/" target="_blank">Weibo</a>
            </span>
            
              <span class="links-of-author-item">
              <a href="http://blkstone.github.io/" target="_blank">DouBan</a>
            </span>
            
              <span class="links-of-author-item">
              <a href="http://blkstone.github.io/" target="_blank">ZhiHu</a>
            </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

      </div>

      
        <div class="post-toc-wrap sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Installing_Java"><span class="nav-number">1.</span> <span class="nav-text">Installing Java</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adding_a_dedicated_Hadoop_user"><span class="nav-number">2.</span> <span class="nav-text">Adding a dedicated Hadoop user</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Installing_SSH"><span class="nav-number">3.</span> <span class="nav-text">Installing SSH</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Create_and_Setup_SSH_Certificates"><span class="nav-number">4.</span> <span class="nav-text">Create and Setup SSH Certificates</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Install_Hadoop"><span class="nav-number">5.</span> <span class="nav-text">Install Hadoop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Setup_Configuration_Files"><span class="nav-number">6.</span> <span class="nav-text">Setup Configuration Files</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#~/-bashrc"><span class="nav-number">6.1.</span> <span class="nav-text">~/.bashrc</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#/usr/local/hadoop/etc/hadoop/hadoop-env-sh"><span class="nav-number">6.2.</span> <span class="nav-text">/usr/local/hadoop/etc/hadoop/hadoop-env.sh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#/usr/local/hadoop/etc/hadoop/core-site-xml"><span class="nav-number">6.3.</span> <span class="nav-text">/usr/local/hadoop/etc/hadoop/core-site.xml</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#/usr/local/hadoop/etc/hadoop/mapred-site-xml"><span class="nav-number">6.4.</span> <span class="nav-text">/usr/local/hadoop/etc/hadoop/mapred-site.xml</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#/usr/local/hadoop/etc/hadoop/hdfs-site-xml"><span class="nav-number">6.5.</span> <span class="nav-text">/usr/local/hadoop/etc/hadoop/hdfs-site.xml</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Format_the_New_Hadoop_Filesystem"><span class="nav-number">7.</span> <span class="nav-text">Format the New Hadoop Filesystem</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Starting_Hadoop"><span class="nav-number">8.</span> <span class="nav-text">Starting Hadoop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Stopping_Hadoop"><span class="nav-number">9.</span> <span class="nav-text">Stopping Hadoop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop_Web_Interfaces"><span class="nav-number">10.</span> <span class="nav-text">Hadoop Web Interfaces</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#参考资料"><span class="nav-number">11.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </div>
      

    </div>
  </div>


    </div>

    <div id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; &nbsp;  2015 - 
  2016
  <span class="with-love">
    <i class="icon-heart"></i>
  </span>
  <span class="author">Ray</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 強力驅動
</div>

<div class="theme-info">
  主題 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </div>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.3"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.3"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.3" id="motion.global"></script>



  <script type="text/javascript" src="/js/search-toggle.js"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.3" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var $sidebarInner = $('.sidebar-inner');
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.didShow', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;
          var self = this;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      $(indicator).velocity('stop').velocity({
        opacity: action === 'show' ? 0.4 : 0
      }, { duration: 100 });
    }

  });
</script>


  <script type="text/javascript" id="sidebar.nav">
    $(document).ready(function () {
      var html = $('html');

      $('.sidebar-nav li').on('click', function () {
        var item = $(this);
        var activeTabClassName = 'sidebar-nav-active';
        var activePanelClassName = 'sidebar-panel-active';
        if (item.hasClass(activeTabClassName)) {
          return;
        }

        var currentTarget = $('.' + activePanelClassName);
        var target = $('.' + item.data('target'));

        currentTarget.velocity('transition.slideUpOut', 200, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', 200)
            .addClass(activePanelClassName);
        });

        item.siblings().removeClass(activeTabClassName);
        item.addClass(activeTabClassName);
      });

      $('.post-toc a').on('click', function (e) {
        e.preventDefault();
        var offset = $(escapeSelector(this.getAttribute('href'))).offset().top;
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        });
      });

      // Expand sidebar on post detail page by default, when post has a toc.
      var $tocContent = $('.post-toc-content');
      if (isDesktop() && CONFIG.sidebar === 'post') {
        if ($tocContent.length > 0 && $tocContent.html().trim().length > 0) {
          displaySidebar();
        }
      }
    });
  </script>




  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
    });
  </script>

  
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  
  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"blkstone"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  


  
  

</body>
</html>
